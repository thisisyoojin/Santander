{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santander Product Recommendation\n",
    "\n",
    "### Part 2. Preprocessing\n",
    "\n",
    "As I could see from EDA, some data has outliers, missing values and wrong data type. They should be cleaned and split for cross validation to train the model.\n",
    "\n",
    "### 2-1.  Assemble data together\n",
    "\n",
    "For preprocessing all data, we assemble train data and test data.<br>\n",
    "Also, I removed data with no product data, which will not be helpful for training the model.  As test data is provided for prediction, it doesn't have product data. For now, I filled the data as 0 for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thisi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (5,8,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\thisi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "trn = pd.read_csv('input/train_ver2.csv')\n",
    "tst = pd.read_csv('input/test_ver2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12020685, 48)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prods = trn.columns[24:]\n",
    "\n",
    "trn[prods] = trn[prods].fillna(0.0).astype(np.int8)\n",
    "no_product = trn[prods].sum(axis=1) == 0\n",
    "trn = trn[~no_product]\n",
    "\n",
    "for col in trn.columns[24:]:\n",
    "    tst[col] = 0\n",
    "    \n",
    "df = pd.concat([trn, tst], axis=0)\n",
    "del trn, tst\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2.  Cleaning Data\n",
    "\n",
    "In this part, I removed unnecessary/duplicated data for better prediction.<br>\n",
    "\n",
    "#### Drop columns\n",
    "From EDA, I knew 'nomprov' is duplicated and 'tipodom' has 0 standard derivation.<br>\n",
    "Also, over 90% of values are missing in the features, I removed the data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12020685, 44)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_ = ['nomprov', 'tipodom']\n",
    "\n",
    "mask = (df.iloc[:,:24].isnull().sum() / df.shape[0]) > 0.9\n",
    "drop_ += mask[mask].index.tolist()\n",
    "\n",
    "df.drop(drop_, axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical columns\n",
    "\n",
    "First, I corrected data types, remove noise data, and fill missing values as -99 for penalty. <br>\n",
    "Then I labeled these columns to convert string to numeric value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "\n",
    "# Converting data type\n",
    "flt_to_obj = ['ind_nuevo', 'indrel', 'ind_actividad_cliente']\n",
    "df[flt_to_obj] = df[flt_to_obj].astype('O')\n",
    "\n",
    "# Remove noise\n",
    "df['indrel_1mes'].replace({'1.0':1, '1':1, 2.0:2, '2.0':2,'2':2, 3.0:3, '3':3, '3.0': 3, '4':4, 4.0:4,'4.0': 4, 'P':5}, inplace=True)\n",
    "df['tiprel_1mes'].replace('N', 'I', inplace=True)\n",
    "\n",
    "# Filling missing values and factorize it\n",
    "categorical_cols = ['ind_empleado', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'indfall', 'segmento', 'indrel_1mes'] + flt_to_obj + ['pais_residencia', 'canal_entrada','cod_prov']\n",
    "df[categorical_cols] = df[categorical_cols].fillna(-99)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col], _ = df[col].factorize()\n",
    "    \n",
    "features += categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical columns\n",
    "\n",
    "For numerical columns, I changed the data type to int and fill missing value and replace outliers as -99 for penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 타입 숫자로 수정\n",
    "def str_to_int(series):    \n",
    "    if type(series) is str:\n",
    "        return int(series.strip())\n",
    "    else:\n",
    "        return series\n",
    "\n",
    "#수치형 변수 1:age\n",
    "df['age'].replace(' NA',-99, inplace=True)\n",
    "df['age'] = df['age'].apply(str_to_int).astype(np.int8)\n",
    "\n",
    "#수치형 변수 2:antiguedad\n",
    "df['antiguedad'].replace(['     NA','-999999',-999999], -99, inplace=True)\n",
    "df['antiguedad'] = df['antiguedad'].apply(str_to_int).astype(np.int8)\n",
    "\n",
    "#수치형 변수3: renta\n",
    "df['renta'].fillna(-99, inplace=True)\n",
    "df['renta'].replace('         NA', -99, inplace=True)\n",
    "df['renta'] = df['renta'].apply(float).round()\n",
    "\n",
    "# 학습에 사용할 수치형 변수를 features에 추구한다.\n",
    "features += ['age', 'antiguedad' ,'renta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3.  Feature Engineering\n",
    "\n",
    "Created lagged-features(1 month behind) and added them on the feature list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜를 숫자로 변환하는 함수이다. 2015-01-28은 1, 2016-06-28은 18로 변환된다\n",
    "def date_to_int(str_date):\n",
    "    Y, M, D = [int(a) for a in str_date.strip().split(\"-\")] \n",
    "    int_date = (int(Y) - 2015) * 12 + int(M)\n",
    "    return int_date\n",
    "\n",
    "# 날짜를 숫자로 변환하여 int_date에 저장한다\n",
    "df['int_date'] = df['fecha_dato'].map(date_to_int).astype(np.int8)\n",
    "\n",
    "# 데이터를 복사하고, int_date 날짜에 1을 더하여 lag를 생성한다. 변수명에 _prev를 추가한다.\n",
    "df_lag = df.copy()\n",
    "df_lag.columns = [col+'_prev' if col not in ['ncodpers', 'int_date'] else col for col in df.columns]\n",
    "df_lag['int_date'] += 1\n",
    "\n",
    "# 원본 데이터와 lag 데이터를 ncodper와 int_date 기준으로 합친다. Lag 데이터의 int_date는 1 밀려 있기 때문에, 저번 달의 제품 정보가 삽입된다.\n",
    "df_trn = df.merge(df_lag, on=['ncodpers','int_date'], how='left')\n",
    "\n",
    "# 메모리 효율을 위해 불필요한 변수를 메모리에서 제거한다\n",
    "del df, df_lag\n",
    "\n",
    "# 저번 달의 제품 정보가 존재하지 않을 경우를 대비하여 0으로 대체한다.\n",
    "df_trn.fillna(0, inplace=True)\n",
    "\n",
    "# lag-1 변수를 추가한다.\n",
    "features += [f+'_prev' for f in features]\n",
    "features += [p+'_prev' for p in prods]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Additional features will be month and year from 'fecha_alta', which indicates the date customer opened account for first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 변수에서 연도와 월 정보를 추출한다.\n",
    "df_trn['fecha_alta_month'] = df_trn['fecha_alta'].map(lambda x: 0.0 if x.__class__ in [int,float] else float(x.split('-')[1])).astype(np.int8)\n",
    "df_trn['fecha_alta_year'] = df_trn['fecha_alta'].map(lambda x: 0.0 if x.__class__ in [int,float] else float(x.split('-')[0])).astype(np.int16)\n",
    "\n",
    "features += ['fecha_alta_month', 'fecha_alta_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4. Data Split\n",
    "\n",
    "After cleaning data, I split data into train/test for cross validation.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vld_date = '2016-05-28'\n",
    "tst_date = '2016-06-28'\n",
    "\n",
    "tst_all = df_trn[df_trn['fecha_dato'] == tst_date]\n",
    "trn = df_trn[df_trn['fecha_dato']< tst_date]\n",
    "\n",
    "del df_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input/vlds.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'vld_all': trn\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For validation process, I extracted the data of customers who actually buy new products. <br>\n",
    "Based on this, I chose 16 products newly purchased than other products, which will be target class.<br>\n",
    "Other 8 classes and non-additional data will be 17th class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터에서 신규 구매 건수만 추출한다.\n",
    "X = []\n",
    "Y = []\n",
    "for i, prod in enumerate(prods):\n",
    "    prev = prod + '_prev'\n",
    "    prX = trn[(trn[prod] == 1) & (trn[prev] == 0)]\n",
    "    prY = np.zeros(prX.shape[0], dtype=np.int8) + i\n",
    "    X.append(prX)\n",
    "    Y.append(prY)\n",
    "\n",
    "XY = pd.concat(X)\n",
    "Y = np.hstack(Y)\n",
    "XY['y'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 17, 18, 19, 21, 22, 23],\n",
       " [0, 1, 3, 10, 14, 15, 16, 20])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = sorted(XY[XY['fecha_dato']>'2015-05-28']['y'].value_counts().index.tolist()[:16])\n",
    "non_target = sorted(XY[XY['fecha_dato']>'2015-05-28']['y'].value_counts().index.tolist()[16:])\n",
    "target, non_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thisi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\thisi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "prevs = [prod+'_prev' for prod in prods]\n",
    "\n",
    "arr = trn[prods].values - trn[prevs].values\n",
    "arr = np.sum(arr, axis=1)\n",
    "non_index = []\n",
    "for i in range(len(arr)):\n",
    "    if arr[i]==0:\n",
    "        non_index.append(i)\n",
    "        \n",
    "trn_non = trn.iloc[non_index]\n",
    "trn_non['y'] = 24\n",
    "trn_non['target'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thisi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\thisi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "tarX=[]\n",
    "for i,t in enumerate(target):\n",
    "    tX = XY[XY['y'] == t]\n",
    "    tX['target'] = i\n",
    "    tarX.append(tX)\n",
    "\n",
    "for nt in non_target:\n",
    "    tX = XY[XY['y'] == nt]\n",
    "    tX['target'] = 16\n",
    "    tarX.append(tX)\n",
    "\n",
    "tarX.append(trn_non)\n",
    "del trn_non, XY\n",
    "\n",
    "trn_17 = pd.concat(tarX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, I saved the metadata and processed data as file for use in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input/meta_data.pkl', 'wb') as ff:\n",
    "    pickle.dump({\n",
    "        'features':features,\n",
    "        'prods':prods,\n",
    "        'target':target\n",
    "    }, ff)\n",
    "    \n",
    "with open('input/processed_data.pkl', 'wb') as fff:\n",
    "    pickle.dump({\n",
    "        'trn_all': trn_17,\n",
    "        'tst_all': tst_all\n",
    "    }, fff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
