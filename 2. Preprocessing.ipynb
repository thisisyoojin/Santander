{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santander Product Recommendation\n",
    "\n",
    "* The aim is to\n",
    "* Modeling: Ensemble LightGBM, XGboost, NN(5 layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Prepare Data\n",
    "\n",
    "* Load train and test data\n",
    "* Assemble data together to preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and load train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thisi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (5,8,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\thisi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "trn = pd.read_csv('../input/train_ver2.csv')\n",
    "tst = pd.read_csv('../input/test_ver2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>sexo</th>\n",
       "      <th>age</th>\n",
       "      <th>fecha_alta</th>\n",
       "      <th>ind_nuevo</th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>indrel</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_hip_fin_ult1</th>\n",
       "      <th>ind_plan_fin_ult1</th>\n",
       "      <th>ind_pres_fin_ult1</th>\n",
       "      <th>ind_reca_fin_ult1</th>\n",
       "      <th>ind_tjcr_fin_ult1</th>\n",
       "      <th>ind_valo_fin_ult1</th>\n",
       "      <th>ind_viv_fin_ult1</th>\n",
       "      <th>ind_nomina_ult1</th>\n",
       "      <th>ind_nom_pens_ult1</th>\n",
       "      <th>ind_recibo_ult1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1375586</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>35</td>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050611</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050612</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050613</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>22</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050614</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fecha_dato  ncodpers ind_empleado pais_residencia sexo  age  fecha_alta  \\\n",
       "0  2015-01-28   1375586            N              ES    H   35  2015-01-12   \n",
       "1  2015-01-28   1050611            N              ES    V   23  2012-08-10   \n",
       "2  2015-01-28   1050612            N              ES    V   23  2012-08-10   \n",
       "3  2015-01-28   1050613            N              ES    H   22  2012-08-10   \n",
       "4  2015-01-28   1050614            N              ES    V   23  2012-08-10   \n",
       "\n",
       "   ind_nuevo antiguedad  indrel  ... ind_hip_fin_ult1 ind_plan_fin_ult1  \\\n",
       "0        0.0          6     1.0  ...                0                 0   \n",
       "1        0.0         35     1.0  ...                0                 0   \n",
       "2        0.0         35     1.0  ...                0                 0   \n",
       "3        0.0         35     1.0  ...                0                 0   \n",
       "4        0.0         35     1.0  ...                0                 0   \n",
       "\n",
       "  ind_pres_fin_ult1 ind_reca_fin_ult1 ind_tjcr_fin_ult1 ind_valo_fin_ult1  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "  ind_viv_fin_ult1 ind_nomina_ult1  ind_nom_pens_ult1  ind_recibo_ult1  \n",
       "0                0             0.0                0.0                0  \n",
       "1                0             0.0                0.0                0  \n",
       "2                0             0.0                0.0                0  \n",
       "3                0             0.0                0.0                0  \n",
       "4                0             0.0                0.0                0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns saving Customer varables/\n",
    "Through EDA, we notice some data doesn't have any product data, which will be not helpful for building predicting model. Remove data of customers who doesn't own any products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prods = trn.columns[24:]\n",
    "\n",
    "trn[prods] = trn[prods].fillna(0.0).astype(np.int8)\n",
    "no_product = trn[prods].sum(axis=1) == 0\n",
    "trn = trn[~no_product]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put train data and test data altogether for preprocessing data. As this project is from Kaggle, test data doesn't have product data. For now, we fill the data as 0 for preprocessing.<br>\n",
    "After making all df, remove unnecessary data for making a space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12020685, 48)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in trn.columns[24:]:\n",
    "    tst[col] = 0\n",
    "    \n",
    "df = pd.concat([trn, tst], axis=0)\n",
    "del trn, tst\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unnecessary/duplicated data\n",
    "* std 1:\n",
    "* duplicated: cod_prov\n",
    "* Of Customer variables, missing value is more than 90%, remove the data for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12020685, 44)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_ = ['nomprov', 'tipodom']\n",
    "\n",
    "mask = (df.iloc[:,:24].isnull().sum() / df.shape[0]) > 0.9\n",
    "drop_ += mask[mask].index.tolist()\n",
    "\n",
    "df.drop(drop_, axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Categorical columns. \n",
    "<br>\n",
    "1) 데이터 타입 맞추기:float to object, ind_nuevo, indrel, ind_actividad_cliente<br>\n",
    "2) 이상치 수정하기 : 'indrel_1mes', ''tiprel_1mes'<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data type\n",
    "flt_to_obj = ['ind_nuevo', 'indrel', 'ind_actividad_cliente']\n",
    "df[flt_to_obj] = df[flt_to_obj].astype('O')\n",
    "\n",
    "# Remove noise\n",
    "df['indrel_1mes'].replace({'1.0':1, '1':1, 2.0:2, '2.0':2,'2':2, 3.0:3, '3':3, '3.0': 3, '4':4, 4.0:4,'4.0': 4, 'P':5}, inplace=True)\n",
    "df['tiprel_1mes'].replace('N', 'I', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['ind_empleado', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'indfall', 'segmento', 'indrel_1mes'] + flt_to_obj + ['pais_residencia', 'canal_entrada','cod_prov']\n",
    "\n",
    "df[categorical_cols] = df[categorical_cols].fillna(-99)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col], _ = df[col].factorize()\n",
    "    \n",
    "features += categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical columns\n",
    "* age: Age\n",
    "* antiguedad: Customer seniority (in months)\n",
    "* renta : Gross income of the household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 타입 숫자로 수정\n",
    "def str_to_int(series):    \n",
    "    if type(series) is str:\n",
    "        return int(series.strip())\n",
    "    else:\n",
    "        return series\n",
    "\n",
    "#수치형 변수 1:age\n",
    "df['age'].replace(' NA',-99, inplace=True)\n",
    "df['age'] = df['age'].apply(str_to_int).astype(np.int8)\n",
    "\n",
    "#수치형 변수 2:antiguedad\n",
    "df['antiguedad'].replace(['     NA','-999999',-999999], -99, inplace=True)\n",
    "df['antiguedad'] = df['antiguedad'].apply(str_to_int).astype(np.int8)\n",
    "\n",
    "#수치형 변수3: renta\n",
    "df['renta'].fillna(-99, inplace=True)\n",
    "df['renta'].replace('         NA', -99, inplace=True)\n",
    "df['renta'] = df['renta'].apply(float).round()\n",
    "\n",
    "# 학습에 사용할 수치형 변수를 features에 추구한다.\n",
    "features += ['age', 'antiguedad' ,'renta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify newly added products, make lag-1 product data\n",
    "* Step 1) convert date to int to see order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 변수에서 연도와 월 정보를 추출한다.\n",
    "df['fecha_alta_month'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['fecha_alta_year'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜를 숫자로 변환하는 함수이다. 2015-01-28은 1, 2016-06-28은 18로 변환된다\n",
    "def date_to_int(str_date):\n",
    "    Y, M, D = [int(a) for a in str_date.strip().split(\"-\")] \n",
    "    int_date = (int(Y) - 2015) * 12 + int(M)\n",
    "    return int_date\n",
    "\n",
    "# 날짜를 숫자로 변환하여 int_date에 저장한다\n",
    "df['int_date'] = df['fecha_dato'].map(date_to_int).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 복사하고, int_date 날짜에 1을 더하여 lag를 생성한다. 변수명에 _prev를 추가한다.\n",
    "df_lag = df.copy()\n",
    "df_lag.columns = [col+'_prev' if col not in ['ncodpers', 'int_date'] else col for col in df.columns]\n",
    "df_lag['int_date'] += 1\n",
    "\n",
    "# 원본 데이터와 lag 데이터를 ncodper와 int_date 기준으로 합친다. Lag 데이터의 int_date는 1 밀려 있기 때문에, 저번 달의 제품 정보가 삽입된다.\n",
    "df_trn = df.merge(df_lag, on=['ncodpers','int_date'], how='left')\n",
    "\n",
    "# 메모리 효율을 위해 불필요한 변수를 메모리에서 제거한다\n",
    "del df, df_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저번 달의 제품 정보가 존재하지 않을 경우를 대비하여 0으로 대체한다.\n",
    "df_trn.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag-1 변수를 추가한다.\n",
    "features += [f+'_prev' for f in features]\n",
    "features += [p+'_prev' for p in prods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features += ['fecha_alta_month', 'fecha_alta_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and Data Split\n",
    "<br>\n",
    "First, we are going to validate data with train data and also test data.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vld_date = '2016-05-28'\n",
    "tst_date = '2016-06-28'\n",
    "\n",
    "tst_vld = df_trn[df_trn['fecha_dato']== vld_date]\n",
    "tst_all = df_trn[df_trn['fecha_dato'] == tst_date]\n",
    "\n",
    "trn = df_trn[df_trn['fecha_dato']< tst_date]\n",
    "\n",
    "#del df_trn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For validation process, we extract data of customer who actually buy new products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터에서 신규 구매 건수만 추출한다.\n",
    "X = []\n",
    "Y = []\n",
    "for i, prod in enumerate(prods):\n",
    "    prev = prod + '_prev'\n",
    "    prX = trn[(trn[prod] == 1) & (trn[prev] == 0)]\n",
    "    prY = np.zeros(prX.shape[0], dtype=np.int8) + i\n",
    "    X.append(prX)\n",
    "    Y.append(prY)\n",
    "\n",
    "XY = pd.concat(X)\n",
    "Y = np.hstack(Y)\n",
    "XY['y'] = Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently bought products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 17, 18, 19, 21, 22, 23],\n",
       " [0, 1, 3, 10, 14, 15, 16, 20])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = sorted(XY[XY['fecha_dato']>'2015-05-28']['y'].value_counts().index.tolist()[:16])\n",
    "non_target = sorted(XY[XY['fecha_dato']>'2015-05-28']['y'].value_counts().index.tolist()[16:])\n",
    "target, non_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there was no addition, make it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevs = [prod+'_prev' for prod in prods]\n",
    "\n",
    "arr = trn[prods].values - trn[prevs].values\n",
    "arr = np.sum(arr, axis=1)\n",
    "non_index = []\n",
    "for i in range(len(arr)):\n",
    "    if arr[i]==0:\n",
    "        non_index.append(i)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11091070, 1778875, 9676014)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.shape[0], XY.shape[0]len(non_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_non = trn.iloc[non_index]\n",
    "trn_non['y'] = 24\n",
    "trn_non['target'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thisi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\thisi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "tarX=[]\n",
    "for i,t in enumerate(target):\n",
    "    tX = XY[XY['y'] == t]\n",
    "    tX['target'] = i\n",
    "    tarX.append(tX)\n",
    "\n",
    "for nt in non_target:\n",
    "    tX = XY[XY['y'] == nt]\n",
    "    tX['target'] = 16\n",
    "    tarX.append(tX)\n",
    "\n",
    "tarX.append(trn_non)\n",
    "del trn_non, XY\n",
    "\n",
    "trn_17 = pd.concat(tarX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/meta_data.pkl', 'wb') as fout:\n",
    "    pickle.dump({\n",
    "        'features':features,\n",
    "        'prods':prods,\n",
    "        'target':target\n",
    "    }, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/processed_data.pkl', 'wb') as foutt:\n",
    "    pickle.dump({\n",
    "        'trn_all': trn_17,\n",
    "        'tst_vld': tst_vld,\n",
    "        'tst_all': tst_all\n",
    "    }, foutt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
